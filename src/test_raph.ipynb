{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier.py          baselines.py           pred.csv\r\n",
      "TEST.ipynb             challengeFunctions.py  test_raph.ipynb\r\n",
      "Untitled.ipynb         kernels.py\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/           main.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xte0.csv',\n",
       " 'Xte0_mat50.csv',\n",
       " 'Xte1.csv',\n",
       " 'Xte1_mat50.csv',\n",
       " 'Xte2.csv',\n",
       " 'Xte2_mat50.csv',\n",
       " 'Xtr0.csv',\n",
       " 'Xtr0_mat50.csv',\n",
       " 'Xtr1.csv',\n",
       " 'Xtr1_mat50.csv',\n",
       " 'Xtr2.csv',\n",
       " 'Xtr2_mat50.csv',\n",
       " 'Ytr0.csv',\n",
       " 'Ytr1.csv',\n",
       " 'Ytr2.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir = '../data/'\n",
    "os.listdir(data_dir)\n",
    "files = os.listdir(data_dir)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sequences directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(n,t):\n",
    "    \"\"\"\n",
    "    n: index of the dataset to be loaded\n",
    "    t:type of data , 'train' or 'test'\n",
    "    \"\"\"\n",
    "    if(t=='test'):\n",
    "        path = data_dir+'Xte'+str(n) +'.csv'\n",
    "        data = pd.read_csv(path,header=-1)\n",
    "        X = data.as_matrix()\n",
    "        return X\n",
    "    if(t=='train'):\n",
    "        xpath = data_dir+'Xtr' +str(n) +'.csv'\n",
    "        ypath = data_dir+'Ytr' +str(n) +'.csv'\n",
    "        data = pd.read_csv(xpath,header=-1)\n",
    "        labels = pd.read_csv(data_dir+'Ytr0.csv')\n",
    "        X = data.as_matrix()\n",
    "        X = X.reshape(np.shape(X)[0]) # Sequences in String format\n",
    "        Y = labels['Bound'].as_matrix()\n",
    "        return X,Y\n",
    "    else:\n",
    "        print('unknown type of dataset')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X,Y=load_data(0,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binary encoding\n",
    "D = {'A':[1,0,0,0],\n",
    "    'C':[0,1,0,0],\n",
    "    'T':[0,0,1,0],\n",
    "    'G':[0,0,0,1]}\n",
    "\n",
    "def encode(sequence):\n",
    "    code=[]\n",
    "    for l in list(sequence):\n",
    "        code+=(D[l])\n",
    "    return code\n",
    "\n",
    "#X = np.array([encode(x) for x in X])\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:1 ,C:2 , T:3, G:4\n",
    "code_dict={\n",
    "    'A':1,\n",
    "    'C':2,\n",
    "    'T':3,\n",
    "    'G':4\n",
    "}\n",
    "def code(string):\n",
    "    return sum([code_dict[s]*4**(len(s)-k+1) for k,s in enumerate(string) ])\n",
    "\n",
    "def phi(x,k=3):\n",
    "    xa=np.ravel(x) # ensure that second dimension of x is zero\n",
    "    L=len(xa[0]) # each element of xa is a string\n",
    "    n=np.shape(x)[0]\n",
    "    \n",
    "    p=sum([4*4**j for j in range(k) ]) # dimension of the sparse representation \n",
    "    \n",
    "    occs=np.zeros((n,p))\n",
    "    for i,s in enumerate(xa):\n",
    "        for j in range(L-k):\n",
    "            occs[i,code(s[j:j+k])-1]+=1\n",
    "            \n",
    "    return occs\n",
    "\n",
    "\n",
    "def spectrum_kernel(s,t):\n",
    "    phi1=phi(s)\n",
    "    phi2=phi(t)\n",
    "    return np.dot(phi1,phi2)/np.sqrt(np.dot(phi1,phi1)*np.dot(phi2,phi2))\n",
    "\n",
    "Xtr0,Ytr0=load_data(0,'train')\n",
    "Xtr1,Ytr1=load_data(1,'train')\n",
    "Xtr2,Ytr2=load_data(2,'train')\n",
    "\n",
    "\n",
    "\n",
    "Xte0=load_data(0,'test')\n",
    "Xtr1=load_data(1,'test')\n",
    "Xtr2=load_data(2,'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 84)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(phi(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fixedsub_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a06e126b5f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfixedsub_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fixedsub_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "fixedsub_kernel(X[0:1],X[3:4],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "def generate_uplets(alphabet,n,aux):\n",
    "    if n==0:\n",
    "        return aux\n",
    "    else:\n",
    "        tmp = []\n",
    "        for a in (aux):\n",
    "            for l in alphabet:\n",
    "                tmp.append(l+a)\n",
    "            \n",
    "        return generate_uplets(alphabet,n-1,tmp)\n",
    "    \n",
    "    \n",
    "\n",
    "def spectrum(x,k=3):\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernel of the vector x\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array containing the sequences in string format.\n",
    "        Second dimension must be 1\n",
    "    k : length of substrings to consider\n",
    "    Returns\n",
    "    -------\n",
    "    phix : spectrum representation of x. Array containing for each word\n",
    "            of size k the number of occurences of the word in x\n",
    "    \"\"\"\n",
    "    n = np.shape(x)[0]\n",
    "    k_uplets = generate_uplets('ACTG',k,[''])\n",
    "    \n",
    "    occs = np.zeros((n,len(k_uplets)))\n",
    "    for i,sequence in enumerate(x):\n",
    "        for j,s in enumerate(k_uplets):\n",
    "            occs[i,j]=sequence.count(s)\n",
    "    \n",
    "    return occs\n",
    "\n",
    "def spectrum_kernel(x1,x2,k=3):\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernel between x1 and x2\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp1,tmp2 = x1.reshape(np.shape(x1)[0]),x2.reshape(np.shape(x2)[0])\n",
    "    s1 , s2 = spectrum(tmp1,k),spectrum(tmp2,k)\n",
    "    \n",
    "    \n",
    "    return np.dot(s1,s2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2229815a1827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'str'"
     ]
    }
   ],
   "source": [
    "np.dot(X,X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-128b4b46aefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'manual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrum_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'kernel'"
     ]
    }
   ],
   "source": [
    "reload(Classifier)\n",
    "clf = Classifier.SVM()\n",
    "\n",
    "clf.setKernel(name='manual',f=spectrum_kernel)\n",
    "\n",
    "\n",
    "def fetch_data(Xpath,Ypath=None):\n",
    "    data = pd.read_csv(Xpath,header=-1)\n",
    "    X=data.as_matrix()\n",
    "    X = X.reshape(np.shape(X)[0])\n",
    "    \n",
    "    # If there are no labels\n",
    "    if Ypath==None:\n",
    "        return X\n",
    "        \n",
    "    else:\n",
    "        labels = pd.read_csv(Ypath)\n",
    "        Y=labels['Bound'].as_matrix()\n",
    "        return X,Y\n",
    "    \n",
    "    \n",
    "\n",
    "X0,Y0 = fetch_data(data_dir+'Xtr0.csv',data_dir+'Ytr0.csv')\n",
    "X1,Y1 = fetch_data(data_dir+'Xtr1.csv',data_dir+'Ytr1.csv')\n",
    "X2,Y2 = fetch_data(data_dir+'Xtr2.csv',data_dir+'Ytr2.csv')\n",
    "Xtr = np.concatenate([X0,X1,X2])\n",
    "Ytr = np.concatenate([Y0,Y1,Y2])\n",
    "Xtr=Xtr.reshape([np.shape(Xtr)[0],1])\n",
    "\n",
    "X0 = fetch_data(data_dir+'Xte0.csv')\n",
    "X1 = fetch_data(data_dir+'Xte1.csv')\n",
    "X2 = fetch_data(data_dir+'Xte2.csv')\n",
    "Xte = np.concatenate([X0,X1,X2])\n",
    "Xte=Xte.reshape([np.shape(Xte)[0],1])\n",
    "\n",
    "Ktr = spectrum_kernel(Xtr,Xtr)\n",
    "clf.set_gram(Ktr)\n",
    "\n",
    "clf.train(Xtr,Ytr)\n",
    "\n",
    "Yte = svm.predict(Xte)\n",
    "\n",
    "\n",
    "len(Yte)\n",
    "\n",
    "df = pd.DataFrame(Yte,columns =  ['Bound'])\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('Yte.txt',index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48999999999999999"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_spec = spectrum(X,3)\n",
    "\n",
    "perm = np.random.permutation(2000)\n",
    "tr_idx,test_idx = perm[:1500],perm[1500:]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "Xtr,Xte,Ytr,Yte = X_spec[tr_idx],X_spec[test_idx],Y[tr_idx],Y[test_idx]\n",
    "\n",
    "clf.fit(Xtr,Ytr)\n",
    "\n",
    "clf.score(Xte,Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49533333333333335, 0.49533333333333335]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crossvalidation scores\n",
    "\n",
    "def cross_val(clf,X,Y,n_splits=10):\n",
    "    \"\"\"\n",
    "    Computes the scores of the classifier on cross validation dividing the dataset in n_split parts\n",
    "    \"\"\"\n",
    "    \n",
    "    n,p = np.shape(X)\n",
    "    \n",
    "    \n",
    "    width = n//n_splits\n",
    "    perm = np.random.permutation(n)\n",
    "    splits = [perm[k*width:(k+1)*width] for k in range(n_splits)]\n",
    "    scores = []\n",
    "    for k in range(n_splits):\n",
    "        tr_idx=splits[k]\n",
    "        \n",
    "        test_idx=np.concatenate([splits[i] for i in range(n_splits) if i!=k])\n",
    "        \n",
    "        Xtr,Xte,Ytr,Yte = X_spec[tr_idx],X_spec[test_idx],Y[tr_idx],Y[test_idx]\n",
    "\n",
    "        clf.fit(Xtr,Ytr)\n",
    "        scores.append(clf.score(Xte,Yte))\n",
    "    return scores\n",
    "\n",
    "cross_val(SVC(),X_spec,Y,n_splits=2)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismatch kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mismatch(sequence,k,m):\n",
    "    \"\"\"\n",
    "    Computes the mismatch kernel of the vector x, allowing up to m mismatches \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : sequence\n",
    "    k : length of substrings to consider\n",
    "    Returns\n",
    "    -------\n",
    "    phix : spectrum representation of x. Array containing for each word\n",
    "            of size k the number of occurences of the word in x\n",
    "    \"\"\"\n",
    "    k_uplets = generate_uplets('ACTG',k,[''])\n",
    "    occs = np.zeros(len(k_uplets))\n",
    "    for i,s in enumerate(k_uplets):\n",
    "        \n",
    "        occs[i]=sequence.count(s)\n",
    "    return occs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTCAACTTTTATTGGGCCGCTGTGGCACCAGAATCTACGAATGGCGCCCTCTAGAGTTGTGTAAAGAAGTGGCGTCACCTCATTATAAATAAAAGGTTG'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = X[0]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def B(n,x1,x2,lam):\n",
    "    if n==0 or min(len(x1),len(x2))<n:\n",
    "        return 0\n",
    "    else:\n",
    "        print(n)\n",
    "        a=x1[-1]\n",
    "        b=x2[-1]\n",
    "        x1_new=x1[:-1]\n",
    "        x2_new=x2[:-1]\n",
    "        if a==b:\n",
    "            return lam*B(n,x1_new,x2,lam)+lam*B(n,x1,x2_new,lam)-lam**2*B(n,x1_new,x2_new,lam) + lam**2*B(n-1,x1_new,x2_new,lam)\n",
    "        else:\n",
    "            return lam*B(n,x1_new,x2,lam)+lam*B(n,x1,x2_new,lam)-lam**2*B(n,x1_new,x2_new,lam) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq=X[0]\n",
    "seq[0:3]\n",
    "\n",
    "#substring_kernel(seq,seq)\n",
    "\n",
    "test=np.zeros(100)\n",
    "test is None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Substring Kernel\n",
    "Representation indexed by all the substrings of the string.\n",
    "The value of a given component is the number of occurence of the associated substring in the string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac86033b71e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mallsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mallsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mallsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def allsub(s,t):\n",
    "    \"\"\" \n",
    "    Computes the all-subsequence kernel of the strings s and t.\n",
    "    The returned value is the number of subsequence, including gaps, that \n",
    "    appear in s and t. \n",
    "    Parameters\n",
    "    ----------\n",
    "    s,t: Input strings\n",
    "    tab: Dynamic programming table\n",
    "    Returns\n",
    "    -------\n",
    "    The kernel value\n",
    "    \"\"\"\n",
    "    # Initialize dynamic programming table\n",
    "    n,m=len(s),len(t)\n",
    "    tab = np.ones((n+1,m+1))\n",
    "    P = np.zeros(m+1)\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        last = 0\n",
    "        for k in range(1,m+1):\n",
    "            P[k]=P[last]\n",
    "            if(t[k-1]==s[i-1]):\n",
    "                P[k]=P[last]+tab[i-1][k-1]\n",
    "                last=k\n",
    "        \n",
    "        for k in range(1,m+1):\n",
    "            tab[i][k]=tab[i-1][k] + P[k]\n",
    "            \n",
    "    return tab[-1,-1]\n",
    "\n",
    "def allsub_kernel(s,t):\n",
    "    return allsub(s,t)/np.sqrt(allsub(s,s)*allsub(t,t))\n",
    "\n",
    "allsub(X[0],X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed-length Substring Kernel\n",
    "Representation indexed by all the substrings of the string.\n",
    "The value of a given component is the number of occurence of the associated substring in the string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6296884485463954e+40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fixedsub(s,t,p):\n",
    "    n,m=len(s),len(t)\n",
    "    tab = np.ones((n+1,m+1))\n",
    "\n",
    "    for l in range(1,p+1):\n",
    "        old_tab = tab\n",
    "        tab[0,:]=np.ones(m+1)\n",
    "        for i in range(1,n-p+l):\n",
    "            last=0\n",
    "            P=np.zeros(m+1)\n",
    "            for k in range(1,m+1):\n",
    "                P[k]=P[last]\n",
    "                if t[k-1]==s[i-1]:\n",
    "                    P[k]=P[last]+old_tab[i-1,k-1]\n",
    "                    last=k\n",
    "            for k in range(1,m+1):\n",
    "                tab[i,k]=tab[i-1,k]+P[k]\n",
    "    \n",
    "    return tab[n-1,m-1]\n",
    "         \n",
    "def fixedsub_kernel(s,t,p):\n",
    "    return fixedsub(s,t,p)/np.sqrt(fixedsub(s,s,p)*fixedsub(s,s,p))\n",
    "        \n",
    "fixedsub(X[0],X[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def substring(s,t,p=3,lam=0.7):\n",
    "    \"\"\" \n",
    "    Computes the substring kernel between s and t with subsequence length p and gap-weight lam\n",
    "    \n",
    "    \"\"\"\n",
    "    n,m=len(s),len(t)\n",
    "    dps=np.zeros((n+1,m+1))\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        for j in range(1,m+1):\n",
    "            if(s[i-1]==t[i-1]):\n",
    "                dps[i,j]=lam**2\n",
    "    dp=np.zeros((n+1,m+1))\n",
    "    for l in range(2,p+1):\n",
    "        ker=0\n",
    "        for i in range(1,n):\n",
    "            for j in range(1,m):\n",
    "                dp[i,j]=dps[i,j]+lam*dp[i-1,j]+lam*dp[i,j-1]-lam**2*dp[i-1,j-1]\n",
    "                if(s[i-1]==t[j-1]):\n",
    "                    dps[i,j]=lam**2*dp[i-1,j-1]\n",
    "                    ker=ker+dps[i,j]\n",
    "    return ker\n",
    "\n",
    "def substring_normalized(s,t,p=3,lam=0.7):\n",
    "    return substring(s,t,p,lam)/np.sqrt(substring(s,s,p,lam)*substring(t,t,p,lam))\n",
    "\n",
    "\n",
    "def substring_gram(X,p=3,lam=0.7):\n",
    "    Xa=np.ravel(X) # make sure every component of X is a string\n",
    "    n=np.shape(X)[0]\n",
    "    K=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            K[i,j]=substring_normalized(X[i],X[j],p,lam)\n",
    "    K=(K+K.T)*0.5\n",
    "    return K\n",
    "substring_normalized(X[0],X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y=load_data(0,'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in  0.05414867401123047\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0= time.time()\n",
    "substring(X[0],X[1])\n",
    "print('done in ',time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K=substring_gram(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-5572ace7ae67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprocessnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mspectrum_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-5572ace7ae67>\u001b[0m in \u001b[0;36mspectrum_trie\u001b[0;34m(s, t, p)\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0mprocessnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLs_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLt_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mprocessnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mspectrum_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-5572ace7ae67>\u001b[0m in \u001b[0;36mprocessnode\u001b[0;34m(v, depth, p, Ls, Lt, alphabet)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0mprocessnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLs_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLt_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprocessnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-5572ace7ae67>\u001b[0m in \u001b[0;36mprocessnode\u001b[0;34m(v, depth, p, Ls, Lt, alphabet)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mkern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mLsv_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLsv_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "def spectrum_trie(s,t,p):\n",
    "        Ls={}\n",
    "        Lt={}\n",
    "        Ls['']=[(s[i:i+p],0) for i in range(len(s)-p+1)]\n",
    "        Lt['']=[(t[i:i+p],0) for i in range(len(t)-p+1)]\n",
    "        kern=0\n",
    "\n",
    "        def processnode(v,depth,p,Ls,Lt,alphabet='ACTG'):\n",
    "            \"\"\"\n",
    "            v:current node\n",
    "            depth:current depth in the trie\n",
    "            p:length of the substrings to be considered\n",
    "            Ls,Lt : dictionaries containing the lists associated with the visited nodes\n",
    "            kern: value of the kernel\n",
    "            \"\"\"\n",
    "            Ls_new=Ls\n",
    "            Lt_new=Lt\n",
    "            if (depth==p):\n",
    "                kern=kern+len(Ls[v])*len(Lt[v])\n",
    "            else:\n",
    "                \n",
    "                if(len(Ls[v])*len(Lt[v])!=0):\n",
    "                    Lsv_copy=Ls[v]\n",
    "                    while len(Lsv_copy)!=0:\n",
    "                        u,i=Lsv_copy.pop()\n",
    "                        key=v+u[i+1]\n",
    "                        if not (Ls_new.__contains__(key)):\n",
    "                            Ls_new[key]=[]\n",
    "                        Ls_new[key].append((u,i+1))\n",
    "\n",
    "                    Ltv_copy=Lt[v]\n",
    "\n",
    "                    while len(Ltv_copy)!=0:\n",
    "                        u,i=Ltv_copy.pop()\n",
    "                        key=v+u[i+1]\n",
    "                        if not (Lt_new.__contains__(key)):\n",
    "                            Lt_new[key]=[]\n",
    "                        Lt_new[key].append((u,i+1))\n",
    "                    \n",
    "                    for a in alphabet:\n",
    "                        processnode(v+a,depth+1,Ls_new,Lt_new,alphabet)\n",
    "\n",
    "        processnode('',0,p,Ls,Lt)\n",
    "        return kern\n",
    "spectrum_trie(X[0],X[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '__pycache__',\n",
       " 'baselines.py',\n",
       " 'challengeFunctions.py',\n",
       " 'Classifier.py',\n",
       " 'kernels.py',\n",
       " 'main.py',\n",
       " 'TEST.ipynb',\n",
       " 'Yte.txt']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('kernels/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kernels.src.kernels import spectrum,generate_uplets\n",
    "import pandas as pd\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function spectrum in module kernels.src.kernels:\n",
      "\n",
      "spectrum(x, k=3)\n",
      "    Computes the spectrum kernel of the vector x\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array containing the sequences in string format.\n",
      "    \n",
      "    k : length of substrings to consider\n",
      "    Returns\n",
      "    -------\n",
      "    phix : spectrum representation of x. Array containing for each word\n",
      "            of size k the number of occurences of the word in x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-0f188ff09f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectrum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerate_uplets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkernels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectrum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kernel'"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "data_dir = '../../data_kernel/'\n",
    "\n",
    "# load training data\n",
    "def fetch_data(Xpath,Ypath=None):\n",
    "    \"\"\"\n",
    "    Loads the data and labels , stores them into numpy arrays.\n",
    "    If no Ypath is given, then it is assumed that only a test set is wanted\n",
    "    The returned X is a 1-dimensional array containing strings\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(Xpath,header=-1)\n",
    "    X=data.as_matrix()\n",
    "    X = X.reshape(np.shape(X)[0])\n",
    "    \n",
    "    # If there are no labels\n",
    "    if Ypath==None:\n",
    "        return X\n",
    "        \n",
    "    else:\n",
    "        labels = pd.read_csv(Ypath)\n",
    "        Y=labels['Bound'].as_matrix()\n",
    "        return X,Y\n",
    "    \n",
    "    \n",
    "\n",
    "def plot_acc(Xdir,Ydir,lambs=[0.001,0.01,0.1,1,15,50, 100],k=4):\n",
    "    X,Y=fetch_data(Xdir,Ydir)\n",
    "    X=spectrum(X,k)\n",
    "    Xtrain, Y_train, Xtest, Y_test=cf.splitdata(X,Y)\n",
    "\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    best_test_acc=0\n",
    "    best_lam=lambs[0]\n",
    "    for lamb in lambs:\n",
    "        svm = Classifier.SVM(\"polynomial\")\n",
    "        svm.lamb = lamb\n",
    "\n",
    "        Y_train_svm = 2*(Y_train - 1/2)\n",
    "        Y_test_svm = 2*(Y_test - 1/2)\n",
    "        svm.train(Xtrain, Y_train_svm)\n",
    "        y_pred = svm.predict(Xtrain)\n",
    "        y_pred = y_pred > 0\n",
    "        train_acc.append(cf.classification_accuracy(Y_train, y_pred))\n",
    "        y_pred = svm.predict(Xtest)\n",
    "        y_pred = y_pred > 0\n",
    "        test_acc.append(cf.classification_accuracy(Y_test, y_pred))\n",
    "        \n",
    "        print(test_acc[-1])\n",
    "        if(test_acc[-1]>best_test_acc):\n",
    "            best_test_acc=test_acc[-1]\n",
    "            best_lam=lamb\n",
    "            \n",
    "    plt.semilogx(lambs,train_acc)\n",
    "    plt.semilogx(lambs,test_acc)\n",
    "    plt.legend([\"Training\",'Test'])\n",
    "    plt.show()\n",
    "    return best_lam,best_test_acc\n",
    "\n",
    "best_k=3\n",
    "best_acc=0\n",
    "best_lam=3\n",
    "\n",
    "for k in [3,4,5,6,7]:    \n",
    "    bl,ba = plot_acc(data_dir+'Xtr0.csv',data_dir+'Ytr0.csv',[0.001,0.01,1,10,100],k)\n",
    "    if (ba>best_acc):\n",
    "        best_acc=ba\n",
    "        best_lam=bl\n",
    "        best_k=k\n",
    "\n",
    "best_lam,best_k,best_acc\n",
    "\n",
    "test_acc\n",
    "\n",
    "\n",
    "svm = Classifier.SVM(\"gaussian\")\n",
    "svm.lamb = lamb\n",
    "\n",
    "Y_train_svm = 2*(Y_train - 1/2)\n",
    "Y_test_svm = 2*(Y_test - 1/2)\n",
    "svm.train(Xtrain, Y_train_svm)\n",
    "y_pred = svm.predict(Xtrain)\n",
    "y_pred = y_pred > 0\n",
    "train_acc.append(cf.classification_accuracy(Y_train, y_pred))\n",
    "y_pred = svm.predict(Xtest)\n",
    "y_pred = y_pred > 0\n",
    "test_acc.append(cf.classification_accuracy(Y_test, y_pred))\n",
    "\n",
    "def fetch_data(Xpath,Ypath=None):\n",
    "    data = pd.read_csv(Xpath,header=-1)\n",
    "    X=data.as_matrix()\n",
    "    X = X.reshape(np.shape(X)[0])\n",
    "    \n",
    "    # If there are no labels\n",
    "    if Ypath==None:\n",
    "        return X\n",
    "        \n",
    "    else:\n",
    "        labels = pd.read_csv(Ypath)\n",
    "        Y=labels['Bound'].as_matrix()\n",
    "        return X,Y\n",
    "\n",
    "    \n",
    "\n",
    "X0,Y0 = fetch_data(data_dir+'Xtr0.csv',data_dir+'Ytr0.csv')\n",
    "X0=spectrum(X0)\n",
    "X1,Y1 = fetch_data(data_dir+'Xtr1.csv',data_dir+'Ytr1.csv')\n",
    "X1=spectrum(X1)\n",
    "X2,Y2 = fetch_data(data_dir+'Xtr2.csv',data_dir+'Ytr2.csv')\n",
    "X2=spectrum(X2)\n",
    "\n",
    "Xtr = np.vstack([X0,X1,X2])\n",
    "Ytr = np.hstack([Y0,Y1,Y2])\n",
    "Ytr = 2*(Ytr-1/2)\n",
    "\n",
    "\n",
    "svm=Classifier.SVM(\"polynomial\")\n",
    "svm.lam=10\n",
    "\n",
    "\n",
    "\n",
    "data_dir='../../data_kernel/'\n",
    "\n",
    "#0\n",
    "k0=6\n",
    "X0,Y0 = fetch_data(data_dir+'Xtr0.csv',data_dir+'Ytr0.csv')\n",
    "Y0=2*(Y0-1/2)\n",
    "X0=spectrum(X0,k0)\n",
    "svm = Classifier.SVM(\"polynomial\")\n",
    "svm.lamb = 0.1\n",
    "svm.train(X0, Y0)\n",
    "\n",
    "Xte0 = spectrum(fetch_data(data_dir+'Xte0.csv'),k0)\n",
    "\n",
    "Yte0=svm.predict(Xte0)\n",
    "\n",
    "Yte0= Yte0 > 0\n",
    "\n",
    "#1\n",
    "k1=5\n",
    "X1,Y1 = fetch_data(data_dir+'Xtr1.csv',data_dir+'Ytr1.csv')\n",
    "Y1=2*(Y1-1/2)\n",
    "X1=spectrum(X1,k1)\n",
    "\n",
    "svm = Classifier.SVM(\"polynomial\")\n",
    "svm.lamb = 0.1\n",
    "svm.train(X1, Y1)\n",
    "\n",
    "Xte1 = spectrum(fetch_data(data_dir+'Xte1.csv'),k1)\n",
    "\n",
    "Yte1=svm.predict(Xte1)\n",
    "Yte1= Yte1>0\n",
    "\n",
    "#2\n",
    "k2=6\n",
    "X2,Y2 = fetch_data(data_dir+'Xtr2.csv',data_dir+'Ytr2.csv')\n",
    "Y2=2*(Y2-1/2)\n",
    "X2=spectrum(X2,k2)\n",
    "svm = Classifier.SVM(\"polynomial\")\n",
    "svm.lamb = 100\n",
    "svm.train(X2, Y2)\n",
    "\n",
    "Xte2 = spectrum(fetch_data(data_dir+'Xte2.csv'),k2)\n",
    "Yte2=svm.predict(Xte2)\n",
    "Yte2= Yte2>0\n",
    "\n",
    "\n",
    "# Save result\n",
    "Yte=np.concatenate([Yte0,Yte1,Yte2])\n",
    "Yted=(Yte.astype(int))\n",
    "df = pd.DataFrame(Yted,columns =  ['Bound'])\n",
    "\n",
    "df.head()\n",
    "df.to_csv('Yte.txt',index_label='Id')\n",
    "\n",
    "Yte=np.concatenate([Yte0,Yte1,Yte2])\n",
    "\n",
    "Yted=(Yte.astype(int))\n",
    "\n",
    "np.sum(Yted)\n",
    "\n",
    "df = pd.DataFrame(Yted,columns =  ['Bound'])\n",
    "\n",
    "df.head()\n",
    "df.to_csv('Yte.txt',index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
